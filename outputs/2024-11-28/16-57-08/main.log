[2024-11-28 16:57:10,396][flwr][WARNING] - Both server and strategy were provided, ignoring strategy
[2024-11-28 16:57:10,397][flwr][INFO] - Starting Flower simulation, config: ServerConfig(num_rounds=2, round_timeout=None)
[2024-11-28 16:57:15,559][flwr][INFO] - Flower VCE: Ray initialized with resources: {'object_store_memory': 3153463296.0, 'memory': 6306926592.0, 'node:__internal_head__': 1.0, 'node:172.16.1.8': 1.0, 'GPU': 1.0, 'accelerator_type:G': 1.0, 'CPU': 12.0}
[2024-11-28 16:57:15,560][flwr][INFO] - Flower VCE: Resources for each Virtual Client: {'num_cpus': 6, 'num_gpus': 0.5}
[2024-11-28 16:57:15,567][flwr][INFO] - Flower VCE: Creating VirtualClientEngineActorPool with 2 actors
[2024-11-28 16:57:15,567][flwr][INFO] - Initializing global parameters
[2024-11-28 16:57:15,567][flwr][INFO] - Requesting initial parameters from one random client
[2024-11-28 16:57:18,890][flwr][INFO] - Received initial parameters from one random client
[2024-11-28 16:57:18,890][flwr][INFO] - Evaluating initial parameters
[2024-11-28 16:57:19,088][flwr][ERROR] - Error(s) in loading state_dict for ResNet18Model:
	Missing key(s) in state_dict: "model.layer4.0.downsample.0.weight", "model.layer4.0.downsample.1.weight", "model.layer4.0.downsample.1.bias", "model.layer4.0.downsample.1.running_mean", "model.layer4.0.downsample.1.running_var", "model.layer4.1.conv1.weight", "model.layer4.1.bn1.weight", "model.layer4.1.bn1.bias", "model.layer4.1.bn1.running_mean", "model.layer4.1.bn1.running_var", "model.layer4.1.conv2.weight", "model.layer4.1.bn2.weight", "model.layer4.1.bn2.bias", "model.layer4.1.bn2.running_mean", "model.layer4.1.bn2.running_var", "model.fc.weight", "model.fc.bias". 
	size mismatch for model.bn1.num_batches_tracked: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([]).
	size mismatch for model.layer1.0.conv1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).
	size mismatch for model.layer1.0.bn1.running_var: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for model.layer1.0.conv2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).
	size mismatch for model.layer1.0.bn2.running_mean: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for model.layer1.1.conv1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).
	size mismatch for model.layer1.1.bn1.bias: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for model.layer1.1.conv2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).
	size mismatch for model.layer1.1.bn2.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for model.layer1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for model.layer1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for model.layer1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for model.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).
	size mismatch for model.layer2.0.bn1.num_batches_tracked: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([]).
	size mismatch for model.layer2.0.conv2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).
	size mismatch for model.layer2.0.bn2.running_var: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.layer2.0.downsample.0.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([128, 64, 1, 1]).
	size mismatch for model.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.layer2.1.conv1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).
	size mismatch for model.layer2.1.bn1.bias: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.layer2.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.layer2.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.layer2.1.conv2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).
	size mismatch for model.layer2.1.bn2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.layer2.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.layer2.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.layer2.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for model.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).
	size mismatch for model.layer3.0.bn1.num_batches_tracked: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([]).
	size mismatch for model.layer3.0.conv2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for model.layer3.0.bn2.running_var: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for model.layer3.0.downsample.0.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([256, 128, 1, 1]).
	size mismatch for model.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for model.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for model.layer3.1.conv1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for model.layer3.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for model.layer3.1.bn1.bias: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for model.layer3.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for model.layer3.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for model.layer3.1.conv2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for model.layer3.1.bn2.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for model.layer3.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for model.layer3.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for model.layer3.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for model.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).
	size mismatch for model.layer4.0.bn1.num_batches_tracked: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([]).
	size mismatch for model.layer4.0.conv2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).
	size mismatch for model.layer4.0.bn2.running_var: copying a param with shape torch.Size([2, 512]) from checkpoint, the shape in current model is torch.Size([512]).
[2024-11-28 16:57:19,088][flwr][ERROR] - Your simulation crashed :(. This could be because of several reasons.The most common are: 
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 6, 'num_gpus': 0.5} is not enough for your workload). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 6, 'num_gpus': 0.5}.
